{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlSM8fzQXmjjwnk2Xk/80w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzervenes/Machine-Learning-module/blob/main/e_Portfolio_Activity_CNN_Model_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis draws upon Matthew Wall's BBC article, \"Biased and wrong? Facial recognition tech in the dock,\" alongside my own research. It presents a reflection on the ethical and social implications of facial recognition technology powered by convolutional neural networks (CNNs). The discussion explores the potential benefits of this technology, as well as its limitations, biases, and broader societal impact."
      ],
      "metadata": {
        "id": "0lyHFsx1-ggI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CCTV has the potential to recognise suspected terrorists in crowded spaces and raise alarms to prevent harm to society. However, facial recognition technology is fallible and could misidentify an innocent person, leading to tragic consequences. This raises a serious ethical dilemma: is it justifiable to save many lives at the potential cost of sacrificing an innocent one? Misidentifications not only harm individuals but also devastate their families and communities. Would we feel safer knowing CCTV could prevent terrorist attacks, while also knowing we or our loved ones might be mistakenly targeted?\n",
        "\n",
        "Currently, facial recognition technology faces significant accuracy challenges. It often struggles to differentiate objects from faces and exhibits higher error rates for women and individuals with darker skin tones. These biases arise because the training datasets used to develop such systems are predominantly composed of white, male faces. This lack of diversity in the data reinforces systemic inequalities and creates disproportionately negative outcomes for underrepresented groups. For example, studies have shown that Black individuals are more likely to be misidentified by facial recognition systems. This not only increases the likelihood of false accusations but also deepens existing systemic inequalities, particularly in communities already overrepresented in the criminal justice system.\n",
        "\n",
        "Practical issues also arise. If face coverings are not banned, criminals could evade detection. Conversely, banning face coverings would penalise people protecting themselves from harsh weather or illness, diminishing their quality of life. Should individuals with compromised immune systems be forced to risk their health simply to comply with facial recognition systems? Trials of such technology in the UK have shown error rates as high as 80%, raising questions about the ethics of testing on the public while privacy concerns remain unresolved.\n",
        "\n",
        "This technology also fosters a pervasive sense of surveillance, making people feel constantly watched. Such fear could lead to self-censorship, discouraging lawful activities like protests or altering daily behaviours, and ultimately eroding public trust.\n",
        "\n",
        "Furthermore, accountability is a major concern. Companies like Amazon sell tools like Rekognition FR without taking responsibility for their misuse, leaving customers and developers to shift blame when errors occur. Without clear regulations, who will be held accountable for false accusations?\n",
        "Finally, facial recognition's ability to detect suspicious behaviour poses its own challenges. Traits like avoiding eye contact or fidgeting could reflect medical conditions such as autism or cultural norms, not malintent. Systems must accurately distinguish between genuine threats and benign behaviours to avoid discrimination.\n",
        "\n",
        "Robust regulations are essential to ensure fairness, accountability, and unbiased algorithms. While facial recognition holds promise, its deployment must prioritise ethical considerations and safeguard individual rights. Without robust safeguards, this technology risks exacerbating existing inequalities, eroding public trust, and infringing on individual freedoms.\n"
      ],
      "metadata": {
        "id": "LtEsCxJE-kw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Networks (CNN) - Object Recognition**\n",
        "\n",
        "In this notebook, I will explore and evaluate a Convolutional Neural Network (CNN) model for object recognition. By running the model and modifying the input image index, I aim to analyse the model's prediction accuracy across different test cases. This process will allow me to review key sections of the algorithm, document my observations, and reflect on the model's performance and potential limitations."
      ],
      "metadata": {
        "id": "eKG57MY6-_Rd"
      }
    }
  ]
}